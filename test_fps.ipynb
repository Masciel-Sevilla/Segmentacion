{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyMZB6Ar1otH4vnqOORs9Dvc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Masciel-Sevilla/Segmentacion/blob/main/test_fps.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZigBkjWcYi-h",
        "outputId": "8863a197-d864-4415-975f-078da69d631a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Iniciando Test de Inferencia de FPS en Google Colab ---\n",
            "✅ GPU detectada: 0\n",
            "\n",
            "Cargando 100 imágenes de prueba...\n",
            "Imágenes cargadas. Shape del batch: (100, 128, 128, 3)\n",
            "\n",
            "==================================================\n",
            "Analizando: Modelo S (EfficientNetV2-S)\n",
            "==================================================\n",
            "Cargando modelo: efficient_weed_model_S_best.keras...\n",
            "Modelo cargado exitosamente.\n",
            "Realizando calentamiento de la GPU...\n",
            "Calentamiento completado.\n",
            "\n",
            "--- ¡Iniciando medición de FPS! ---\n",
            "\n",
            "--- 📊 Resultados ---\n",
            "Modelo: Modelo S (EfficientNetV2-S)\n",
            "Imágenes procesadas: 100\n",
            "Tiempo total: 19.02 segundos\n",
            "Tiempo por imagen: 190.22 ms\n",
            "Rendimiento (FPS): 5.26 FPS\n",
            "--------------------\n",
            "\n",
            "==================================================\n",
            "Analizando: Modelo B0 (EfficientNetV2-B0)\n",
            "==================================================\n",
            "Cargando modelo: efficient_weed_model_B0_best.keras...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'aspp_module_4', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'deformable_attention_4', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo cargado exitosamente.\n",
            "Realizando calentamiento de la GPU...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7b561bacbec0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calentamiento completado.\n",
            "\n",
            "--- ¡Iniciando medición de FPS! ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7b561bacbec0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 📊 Resultados ---\n",
            "Modelo: Modelo B0 (EfficientNetV2-B0)\n",
            "Imágenes procesadas: 100\n",
            "Tiempo total: 26.05 segundos\n",
            "Tiempo por imagen: 260.47 ms\n",
            "Rendimiento (FPS): 3.84 FPS\n",
            "--------------------\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "from glob import glob\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# =============================================================================\n",
        "# DEFINIR LAS CLASES PERSONALIZADAS (necesarias para ambos modelos)\n",
        "# =============================================================================\n",
        "\n",
        "class ASPPModule(layers.Layer):\n",
        "    def __init__(self, filters=192, **kwargs):\n",
        "        super(ASPPModule, self).__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.conv_1x1 = layers.Conv2D(filters, 1, padding='same', use_bias=False)\n",
        "        self.bn_1x1 = layers.BatchNormalization()\n",
        "        self.relu_1x1 = layers.ReLU()\n",
        "        self.conv_3x3_6 = layers.Conv2D(filters, 3, padding='same', dilation_rate=6, use_bias=False)\n",
        "        self.bn_3x3_6 = layers.BatchNormalization()\n",
        "        self.relu_3x3_6 = layers.ReLU()\n",
        "        self.conv_3x3_12 = layers.Conv2D(filters, 3, padding='same', dilation_rate=12, use_bias=False)\n",
        "        self.bn_3x3_12 = layers.BatchNormalization()\n",
        "        self.relu_3x3_12 = layers.ReLU()\n",
        "        self.conv_3x3_18 = layers.Conv2D(filters, 3, padding='same', dilation_rate=18, use_bias=False)\n",
        "        self.bn_3x3_18 = layers.BatchNormalization()\n",
        "        self.relu_3x3_18 = layers.ReLU()\n",
        "        self.global_avg_pool = layers.GlobalAveragePooling2D(keepdims=True)\n",
        "        self.conv_1x1_gap = layers.Conv2D(filters, 1, padding='same', use_bias=False)\n",
        "        self.bn_1x1_gap = layers.BatchNormalization()\n",
        "        self.relu_1x1_gap = layers.ReLU()\n",
        "        self.conv_final = layers.Conv2D(filters, 1, padding='same', use_bias=False)\n",
        "        self.bn_final = layers.BatchNormalization()\n",
        "        self.relu_final = layers.ReLU()\n",
        "        self.dropout = layers.Dropout(0.2)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        conv_1x1 = self.relu_1x1(self.bn_1x1(self.conv_1x1(inputs), training=training))\n",
        "        conv_3x3_6 = self.relu_3x3_6(self.bn_3x3_6(self.conv_3x3_6(inputs), training=training))\n",
        "        conv_3x3_12 = self.relu_3x3_12(self.bn_3x3_12(self.conv_3x3_12(inputs), training=training))\n",
        "        conv_3x3_18 = self.relu_3x3_18(self.bn_3x3_18(self.conv_3x3_18(inputs), training=training))\n",
        "        gap = self.global_avg_pool(inputs)\n",
        "        gap = self.relu_1x1_gap(self.bn_1x1_gap(self.conv_1x1_gap(gap), training=training))\n",
        "        gap = tf.image.resize(gap, [input_shape[1], input_shape[2]], method='bilinear')\n",
        "        concat = layers.Concatenate()([conv_1x1, conv_3x3_6, conv_3x3_12, conv_3x3_18, gap])\n",
        "        output = self.relu_final(self.bn_final(self.conv_final(concat), training=training))\n",
        "        output = self.dropout(output, training=training)\n",
        "        return output\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(ASPPModule, self).get_config()\n",
        "        config.update({\"filters\": self.filters})\n",
        "        return config\n",
        "\n",
        "class DeformableAttention(layers.Layer):\n",
        "    def __init__(self, filters, **kwargs):\n",
        "        super(DeformableAttention, self).__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.attention_conv = layers.Conv2D(self.filters, 1, padding='same', activation='sigmoid', name='attention_weights_conv', use_bias=False)\n",
        "        self.bn_attention = layers.BatchNormalization()\n",
        "        self.feature_conv = layers.SeparableConv2D(self.filters, 3, padding='same', name='feature_processing_conv', use_bias=False)\n",
        "        self.bn_feature = layers.BatchNormalization()\n",
        "        self.relu_feature = layers.ReLU()\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        attention_weights = self.bn_attention(self.attention_conv(inputs), training=training)\n",
        "        features = self.relu_feature(self.bn_feature(self.feature_conv(inputs), training=training))\n",
        "        attended_features = features * attention_weights\n",
        "        return attended_features\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(DeformableAttention, self).get_config()\n",
        "        config.update({\"filters\": self.filters})\n",
        "        return config\n",
        "\n",
        "# =============================================================================\n",
        "# CONFIGURACIÓN\n",
        "# =============================================================================\n",
        "# --- ¡NUEVO! Lista de modelos a probar ---\n",
        "MODELS_TO_TEST = [\n",
        "    {'name': 'Modelo S (EfficientNetV2-S)', 'path': 'efficient_weed_model_S_best.keras'},\n",
        "    {'name': 'Modelo B0 (EfficientNetV2-B0)', 'path': 'efficient_weed_model_B0_best.keras'}\n",
        "]\n",
        "\n",
        "TEST_IMAGES_PATH = './Balanced/test/images'\n",
        "IMG_HEIGHT, IMG_WIDTH = 128, 128\n",
        "NUM_IMAGES_TO_TEST = 100\n",
        "\n",
        "# =============================================================================\n",
        "# SCRIPT PRINCIPAL\n",
        "# =============================================================================\n",
        "print(\"--- Iniciando Test de Inferencia de FPS en Google Colab ---\")\n",
        "\n",
        "# Verificar GPU\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    print(f\"✅ GPU detectada: {gpus[0].name.split(':')[-1]}\")\n",
        "else:\n",
        "    print(\"❌ No se detectó ninguna GPU.\")\n",
        "\n",
        "# Cargar imágenes (una sola vez para todos los modelos)\n",
        "print(f\"\\nCargando {NUM_IMAGES_TO_TEST} imágenes de prueba...\")\n",
        "image_paths = sorted(glob(os.path.join(TEST_IMAGES_PATH, '*.jpg')))[:NUM_IMAGES_TO_TEST]\n",
        "test_images = [tf.keras.applications.efficientnet_v2.preprocess_input(tf.image.resize(tf.image.decode_jpeg(tf.io.read_file(path), channels=3), [IMG_HEIGHT, IMG_WIDTH])) for path in image_paths]\n",
        "test_images_batch = np.array(test_images)\n",
        "print(f\"Imágenes cargadas. Shape del batch: {test_images_batch.shape}\")\n",
        "\n",
        "# --- ¡NUEVO! Bucle para probar cada modelo ---\n",
        "for model_info in MODELS_TO_TEST:\n",
        "    model_name = model_info['name']\n",
        "    model_path = model_info['path']\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(f\"Analizando: {model_name}\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    if not os.path.exists(model_path):\n",
        "        print(f\"❌ ERROR: No se encontró el archivo del modelo: {model_path}. Omitiendo.\")\n",
        "        continue\n",
        "\n",
        "    # Cargar el modelo actual\n",
        "    print(f\"Cargando modelo: {model_path}...\")\n",
        "    custom_objects = {'ASPPModule': ASPPModule, 'DeformableAttention': DeformableAttention}\n",
        "    model = tf.keras.models.load_model(model_path, custom_objects=custom_objects, compile=False)\n",
        "    print(\"Modelo cargado exitosamente.\")\n",
        "\n",
        "    # Calentamiento de la GPU para este modelo\n",
        "    print(\"Realizando calentamiento de la GPU...\")\n",
        "    _ = model.predict(test_images_batch[:1], verbose=0)\n",
        "    print(\"Calentamiento completado.\")\n",
        "\n",
        "    # Medición del tiempo\n",
        "    print(\"\\n--- ¡Iniciando medición de FPS! ---\")\n",
        "    start_time = time.time()\n",
        "    _ = model.predict(test_images_batch, verbose=0)\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Cálculo de resultados\n",
        "    total_time = end_time - start_time\n",
        "    num_images = len(test_images_batch)\n",
        "    fps = num_images / total_time\n",
        "    time_per_image_ms = (total_time / num_images) * 1000\n",
        "\n",
        "    print(\"\\n--- 📊 Resultados ---\")\n",
        "    print(f\"Modelo: {model_name}\")\n",
        "    print(f\"Imágenes procesadas: {num_images}\")\n",
        "    print(f\"Tiempo total: {total_time:.2f} segundos\")\n",
        "    print(f\"Tiempo por imagen: {time_per_image_ms:.2f} ms\")\n",
        "    print(f\"Rendimiento (FPS): {fps:.2f} FPS\")\n",
        "    print(\"--------------------\")"
      ]
    }
  ]
}