{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyMZB6Ar1otH4vnqOORs9Dvc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Masciel-Sevilla/Segmentacion/blob/main/test_fps.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZigBkjWcYi-h",
        "outputId": "8863a197-d864-4415-975f-078da69d631a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Iniciando Test de Inferencia de FPS en Google Colab ---\n",
            "‚úÖ GPU detectada: 0\n",
            "\n",
            "Cargando 100 im√°genes de prueba...\n",
            "Im√°genes cargadas. Shape del batch: (100, 128, 128, 3)\n",
            "\n",
            "==================================================\n",
            "Analizando: Modelo S (EfficientNetV2-S)\n",
            "==================================================\n",
            "Cargando modelo: efficient_weed_model_S_best.keras...\n",
            "Modelo cargado exitosamente.\n",
            "Realizando calentamiento de la GPU...\n",
            "Calentamiento completado.\n",
            "\n",
            "--- ¬°Iniciando medici√≥n de FPS! ---\n",
            "\n",
            "--- üìä Resultados ---\n",
            "Modelo: Modelo S (EfficientNetV2-S)\n",
            "Im√°genes procesadas: 100\n",
            "Tiempo total: 19.02 segundos\n",
            "Tiempo por imagen: 190.22 ms\n",
            "Rendimiento (FPS): 5.26 FPS\n",
            "--------------------\n",
            "\n",
            "==================================================\n",
            "Analizando: Modelo B0 (EfficientNetV2-B0)\n",
            "==================================================\n",
            "Cargando modelo: efficient_weed_model_B0_best.keras...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'aspp_module_4', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'deformable_attention_4', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo cargado exitosamente.\n",
            "Realizando calentamiento de la GPU...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7b561bacbec0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calentamiento completado.\n",
            "\n",
            "--- ¬°Iniciando medici√≥n de FPS! ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7b561bacbec0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- üìä Resultados ---\n",
            "Modelo: Modelo B0 (EfficientNetV2-B0)\n",
            "Im√°genes procesadas: 100\n",
            "Tiempo total: 26.05 segundos\n",
            "Tiempo por imagen: 260.47 ms\n",
            "Rendimiento (FPS): 3.84 FPS\n",
            "--------------------\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "from glob import glob\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# =============================================================================\n",
        "# DEFINIR LAS CLASES PERSONALIZADAS (necesarias para ambos modelos)\n",
        "# =============================================================================\n",
        "\n",
        "class ASPPModule(layers.Layer):\n",
        "    def __init__(self, filters=192, **kwargs):\n",
        "        super(ASPPModule, self).__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.conv_1x1 = layers.Conv2D(filters, 1, padding='same', use_bias=False)\n",
        "        self.bn_1x1 = layers.BatchNormalization()\n",
        "        self.relu_1x1 = layers.ReLU()\n",
        "        self.conv_3x3_6 = layers.Conv2D(filters, 3, padding='same', dilation_rate=6, use_bias=False)\n",
        "        self.bn_3x3_6 = layers.BatchNormalization()\n",
        "        self.relu_3x3_6 = layers.ReLU()\n",
        "        self.conv_3x3_12 = layers.Conv2D(filters, 3, padding='same', dilation_rate=12, use_bias=False)\n",
        "        self.bn_3x3_12 = layers.BatchNormalization()\n",
        "        self.relu_3x3_12 = layers.ReLU()\n",
        "        self.conv_3x3_18 = layers.Conv2D(filters, 3, padding='same', dilation_rate=18, use_bias=False)\n",
        "        self.bn_3x3_18 = layers.BatchNormalization()\n",
        "        self.relu_3x3_18 = layers.ReLU()\n",
        "        self.global_avg_pool = layers.GlobalAveragePooling2D(keepdims=True)\n",
        "        self.conv_1x1_gap = layers.Conv2D(filters, 1, padding='same', use_bias=False)\n",
        "        self.bn_1x1_gap = layers.BatchNormalization()\n",
        "        self.relu_1x1_gap = layers.ReLU()\n",
        "        self.conv_final = layers.Conv2D(filters, 1, padding='same', use_bias=False)\n",
        "        self.bn_final = layers.BatchNormalization()\n",
        "        self.relu_final = layers.ReLU()\n",
        "        self.dropout = layers.Dropout(0.2)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        conv_1x1 = self.relu_1x1(self.bn_1x1(self.conv_1x1(inputs), training=training))\n",
        "        conv_3x3_6 = self.relu_3x3_6(self.bn_3x3_6(self.conv_3x3_6(inputs), training=training))\n",
        "        conv_3x3_12 = self.relu_3x3_12(self.bn_3x3_12(self.conv_3x3_12(inputs), training=training))\n",
        "        conv_3x3_18 = self.relu_3x3_18(self.bn_3x3_18(self.conv_3x3_18(inputs), training=training))\n",
        "        gap = self.global_avg_pool(inputs)\n",
        "        gap = self.relu_1x1_gap(self.bn_1x1_gap(self.conv_1x1_gap(gap), training=training))\n",
        "        gap = tf.image.resize(gap, [input_shape[1], input_shape[2]], method='bilinear')\n",
        "        concat = layers.Concatenate()([conv_1x1, conv_3x3_6, conv_3x3_12, conv_3x3_18, gap])\n",
        "        output = self.relu_final(self.bn_final(self.conv_final(concat), training=training))\n",
        "        output = self.dropout(output, training=training)\n",
        "        return output\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(ASPPModule, self).get_config()\n",
        "        config.update({\"filters\": self.filters})\n",
        "        return config\n",
        "\n",
        "class DeformableAttention(layers.Layer):\n",
        "    def __init__(self, filters, **kwargs):\n",
        "        super(DeformableAttention, self).__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.attention_conv = layers.Conv2D(self.filters, 1, padding='same', activation='sigmoid', name='attention_weights_conv', use_bias=False)\n",
        "        self.bn_attention = layers.BatchNormalization()\n",
        "        self.feature_conv = layers.SeparableConv2D(self.filters, 3, padding='same', name='feature_processing_conv', use_bias=False)\n",
        "        self.bn_feature = layers.BatchNormalization()\n",
        "        self.relu_feature = layers.ReLU()\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        attention_weights = self.bn_attention(self.attention_conv(inputs), training=training)\n",
        "        features = self.relu_feature(self.bn_feature(self.feature_conv(inputs), training=training))\n",
        "        attended_features = features * attention_weights\n",
        "        return attended_features\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(DeformableAttention, self).get_config()\n",
        "        config.update({\"filters\": self.filters})\n",
        "        return config\n",
        "\n",
        "# =============================================================================\n",
        "# CONFIGURACI√ìN\n",
        "# =============================================================================\n",
        "# --- ¬°NUEVO! Lista de modelos a probar ---\n",
        "MODELS_TO_TEST = [\n",
        "    {'name': 'Modelo S (EfficientNetV2-S)', 'path': 'efficient_weed_model_S_best.keras'},\n",
        "    {'name': 'Modelo B0 (EfficientNetV2-B0)', 'path': 'efficient_weed_model_B0_best.keras'}\n",
        "]\n",
        "\n",
        "TEST_IMAGES_PATH = './Balanced/test/images'\n",
        "IMG_HEIGHT, IMG_WIDTH = 128, 128\n",
        "NUM_IMAGES_TO_TEST = 100\n",
        "\n",
        "# =============================================================================\n",
        "# SCRIPT PRINCIPAL\n",
        "# =============================================================================\n",
        "print(\"--- Iniciando Test de Inferencia de FPS en Google Colab ---\")\n",
        "\n",
        "# Verificar GPU\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    print(f\"‚úÖ GPU detectada: {gpus[0].name.split(':')[-1]}\")\n",
        "else:\n",
        "    print(\"‚ùå No se detect√≥ ninguna GPU.\")\n",
        "\n",
        "# Cargar im√°genes (una sola vez para todos los modelos)\n",
        "print(f\"\\nCargando {NUM_IMAGES_TO_TEST} im√°genes de prueba...\")\n",
        "image_paths = sorted(glob(os.path.join(TEST_IMAGES_PATH, '*.jpg')))[:NUM_IMAGES_TO_TEST]\n",
        "test_images = [tf.keras.applications.efficientnet_v2.preprocess_input(tf.image.resize(tf.image.decode_jpeg(tf.io.read_file(path), channels=3), [IMG_HEIGHT, IMG_WIDTH])) for path in image_paths]\n",
        "test_images_batch = np.array(test_images)\n",
        "print(f\"Im√°genes cargadas. Shape del batch: {test_images_batch.shape}\")\n",
        "\n",
        "# --- ¬°NUEVO! Bucle para probar cada modelo ---\n",
        "for model_info in MODELS_TO_TEST:\n",
        "    model_name = model_info['name']\n",
        "    model_path = model_info['path']\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(f\"Analizando: {model_name}\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    if not os.path.exists(model_path):\n",
        "        print(f\"‚ùå ERROR: No se encontr√≥ el archivo del modelo: {model_path}. Omitiendo.\")\n",
        "        continue\n",
        "\n",
        "    # Cargar el modelo actual\n",
        "    print(f\"Cargando modelo: {model_path}...\")\n",
        "    custom_objects = {'ASPPModule': ASPPModule, 'DeformableAttention': DeformableAttention}\n",
        "    model = tf.keras.models.load_model(model_path, custom_objects=custom_objects, compile=False)\n",
        "    print(\"Modelo cargado exitosamente.\")\n",
        "\n",
        "    # Calentamiento de la GPU para este modelo\n",
        "    print(\"Realizando calentamiento de la GPU...\")\n",
        "    _ = model.predict(test_images_batch[:1], verbose=0)\n",
        "    print(\"Calentamiento completado.\")\n",
        "\n",
        "    # Medici√≥n del tiempo\n",
        "    print(\"\\n--- ¬°Iniciando medici√≥n de FPS! ---\")\n",
        "    start_time = time.time()\n",
        "    _ = model.predict(test_images_batch, verbose=0)\n",
        "    end_time = time.time()\n",
        "\n",
        "    # C√°lculo de resultados\n",
        "    total_time = end_time - start_time\n",
        "    num_images = len(test_images_batch)\n",
        "    fps = num_images / total_time\n",
        "    time_per_image_ms = (total_time / num_images) * 1000\n",
        "\n",
        "    print(\"\\n--- üìä Resultados ---\")\n",
        "    print(f\"Modelo: {model_name}\")\n",
        "    print(f\"Im√°genes procesadas: {num_images}\")\n",
        "    print(f\"Tiempo total: {total_time:.2f} segundos\")\n",
        "    print(f\"Tiempo por imagen: {time_per_image_ms:.2f} ms\")\n",
        "    print(f\"Rendimiento (FPS): {fps:.2f} FPS\")\n",
        "    print(\"--------------------\")"
      ]
    }
  ]
}