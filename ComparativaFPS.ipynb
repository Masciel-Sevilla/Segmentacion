{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "mount_file_id": "1LnNQVVqOt2wsrCt_9AEVLhJWUpIC3FNY",
      "authorship_tag": "ABX9TyMAwzAYL2bEsxFSKKU+3WkE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Masciel-Sevilla/Segmentacion/blob/main/ComparativaFPS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rt79bwyoPuZE",
        "outputId": "88e6f24e-d398-4c5b-e020-52bb7f493885"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Descomprimiendo /content/Balanced.zip...\n",
            "¬°Descompresi√≥n completada!\n"
          ]
        }
      ],
      "source": [
        "# Paso 1: Descomprimir el dataset (esto solo se hace una vez)\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "zip_path = '/content/Balanced.zip'\n",
        "extract_path = '/content/'\n",
        "\n",
        "# Solo descomprimir si no se ha hecho antes\n",
        "if not os.path.exists(os.path.join(extract_path, 'Balanced')):\n",
        "    print(f\"Descomprimiendo {zip_path}...\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "    print(\"¬°Descompresi√≥n completada!\")\n",
        "else:\n",
        "    print(\"La carpeta 'Balanced' ya existe. Omitiendo descompresi√≥n.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "from glob import glob\n",
        "from tensorflow.keras import layers\n",
        "import pandas as pd\n",
        "\n",
        "class ASPPModule(layers.Layer):\n",
        "    def __init__(self, filters=192, **kwargs):\n",
        "        super(ASPPModule, self).__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.conv_1x1 = layers.Conv2D(filters, 1, padding='same', use_bias=False)\n",
        "        self.bn_1x1 = layers.BatchNormalization()\n",
        "        self.relu_1x1 = layers.ReLU()\n",
        "        self.conv_3x3_6 = layers.Conv2D(filters, 3, padding='same', dilation_rate=6, use_bias=False)\n",
        "        self.bn_3x3_6 = layers.BatchNormalization()\n",
        "        self.relu_3x3_6 = layers.ReLU()\n",
        "        self.conv_3x3_12 = layers.Conv2D(filters, 3, padding='same', dilation_rate=12, use_bias=False)\n",
        "        self.bn_3x3_12 = layers.BatchNormalization()\n",
        "        self.relu_3x3_12 = layers.ReLU()\n",
        "        self.conv_3x3_18 = layers.Conv2D(filters, 3, padding='same', dilation_rate=18, use_bias=False)\n",
        "        self.bn_3x3_18 = layers.BatchNormalization()\n",
        "        self.relu_3x3_18 = layers.ReLU()\n",
        "        self.global_avg_pool = layers.GlobalAveragePooling2D(keepdims=True)\n",
        "        self.conv_1x1_gap = layers.Conv2D(filters, 1, padding='same', use_bias=False)\n",
        "        self.bn_1x1_gap = layers.BatchNormalization()\n",
        "        self.relu_1x1_gap = layers.ReLU()\n",
        "        self.conv_final = layers.Conv2D(filters, 1, padding='same', use_bias=False)\n",
        "        self.bn_final = layers.BatchNormalization()\n",
        "        self.relu_final = layers.ReLU()\n",
        "        self.dropout = layers.Dropout(0.2)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        conv_1x1 = self.relu_1x1(self.bn_1x1(self.conv_1x1(inputs), training=training))\n",
        "        conv_3x3_6 = self.relu_3x3_6(self.bn_3x3_6(self.conv_3x3_6(inputs), training=training))\n",
        "        conv_3x3_12 = self.relu_3x3_12(self.bn_3x3_12(self.conv_3x3_12(inputs), training=training))\n",
        "        conv_3x3_18 = self.relu_3x3_18(self.bn_3x3_18(self.conv_3x3_18(inputs), training=training))\n",
        "        gap = self.global_avg_pool(inputs)\n",
        "        gap = self.relu_1x1_gap(self.bn_1x1_gap(self.conv_1x1_gap(gap), training=training))\n",
        "        gap = tf.image.resize(gap, [input_shape[1], input_shape[2]], method='bilinear')\n",
        "        concat = layers.Concatenate()([conv_1x1, conv_3x3_6, conv_3x3_12, conv_3x3_18, gap])\n",
        "        output = self.relu_final(self.bn_final(self.conv_final(concat), training=training))\n",
        "        output = self.dropout(output, training=training)\n",
        "        return output\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(ASPPModule, self).get_config()\n",
        "        config.update({\"filters\": self.filters})\n",
        "        return config\n",
        "\n",
        "class DeformableAttention(layers.Layer):\n",
        "    def __init__(self, filters, **kwargs):\n",
        "        super(DeformableAttention, self).__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.attention_conv = layers.Conv2D(self.filters, 1, padding='same', activation='sigmoid', name='attention_weights_conv', use_bias=False)\n",
        "        self.bn_attention = layers.BatchNormalization()\n",
        "        self.feature_conv = layers.SeparableConv2D(self.filters, 3, padding='same', name='feature_processing_conv', use_bias=False)\n",
        "        self.bn_feature = layers.BatchNormalization()\n",
        "        self.relu_feature = layers.ReLU()\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        attention_weights = self.bn_attention(self.attention_conv(inputs), training=training)\n",
        "        features = self.relu_feature(self.bn_feature(self.feature_conv(inputs), training=training))\n",
        "        attended_features = features * attention_weights\n",
        "        return attended_features\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(DeformableAttention, self).get_config()\n",
        "        config.update({\"filters\": self.filters})\n",
        "        return config\n",
        "\n",
        "# =============================================================================\n",
        "# CONFIGURACI√ìN\n",
        "# =============================================================================\n",
        "MODELS_TO_TEST = [\n",
        "    {'name': 'Modelo B0 (EfficientNetV2-B0)', 'path': 'efficient_weed_model_B0_best.keras'},\n",
        "    {'name': 'Modelo S (EfficientNetV2-S)', 'path': 'efficient_weed_model_S_best.keras'}\n",
        "]\n",
        "# --- ¬°NUEVO! Lista de batch sizes a probar ---\n",
        "BATCH_SIZES_TO_TEST = [1, 8, 16, 32, 64, 100]\n",
        "\n",
        "TEST_IMAGES_PATH = './Balanced/test/images'\n",
        "IMG_HEIGHT, IMG_WIDTH = 128, 128\n",
        "\n",
        "# =============================================================================\n",
        "# SCRIPT PRINCIPAL\n",
        "# =============================================================================\n",
        "print(\"--- Iniciando Test de Inferencia de FPS en Google Colab ---\")\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    print(f\"‚úÖ GPU detectada: {gpus[0].name.split(':')[-1]}\")\n",
        "else:\n",
        "    print(\"‚ùå No se detect√≥ ninguna GPU.\")\n",
        "\n",
        "# Cargar todas las im√°genes de prueba una sola vez\n",
        "print(f\"\\nCargando im√°genes de prueba...\")\n",
        "all_image_paths = sorted(glob(os.path.join(TEST_IMAGES_PATH, '*.jpg')))\n",
        "all_test_images = [tf.keras.applications.efficientnet_v2.preprocess_input(tf.image.resize(tf.image.decode_jpeg(tf.io.read_file(path), channels=3), [IMG_HEIGHT, IMG_WIDTH])) for path in all_image_paths]\n",
        "all_test_images = np.array(all_test_images)\n",
        "print(f\"Total de im√°genes cargadas: {len(all_test_images)}\")\n",
        "\n",
        "# --- Almacenar resultados ---\n",
        "results = []\n",
        "custom_objects = {'ASPPModule': ASPPModule, 'DeformableAttention': DeformableAttention}\n",
        "\n",
        "# Bucle para probar cada modelo\n",
        "for model_info in MODELS_TO_TEST:\n",
        "    model_name = model_info['name']\n",
        "    model_path = model_info['path']\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(f\"Analizando: {model_name}\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    if not os.path.exists(model_path):\n",
        "        print(f\"‚ùå ERROR: No se encontr√≥ el archivo del modelo: {model_path}. Omitiendo.\")\n",
        "        continue\n",
        "\n",
        "    model = tf.keras.models.load_model(model_path, custom_objects=custom_objects, compile=False)\n",
        "\n",
        "    # Bucle para probar cada batch size\n",
        "    for batch_size in BATCH_SIZES_TO_TEST:\n",
        "        print(f\"\\n--- Probando con Batch Size = {batch_size} ---\")\n",
        "\n",
        "        # Seleccionar el n√∫mero correcto de im√°genes\n",
        "        num_images = (len(all_test_images) // batch_size) * batch_size\n",
        "        if num_images == 0:\n",
        "            print(\"No hay suficientes im√°genes para este batch size. Omitiendo.\")\n",
        "            continue\n",
        "\n",
        "        test_images_batch = all_test_images[:num_images]\n",
        "\n",
        "        # Calentamiento\n",
        "        _ = model.predict(test_images_batch[:batch_size], verbose=0, batch_size=batch_size)\n",
        "\n",
        "        # Medici√≥n\n",
        "        start_time = time.time()\n",
        "        _ = model.predict(test_images_batch, verbose=0, batch_size=batch_size)\n",
        "        end_time = time.time()\n",
        "\n",
        "        total_time = end_time - start_time\n",
        "        fps = num_images / total_time\n",
        "        time_per_image_ms = (total_time / num_images) * 1000\n",
        "\n",
        "        print(f\"Resultados: {fps:.2f} FPS ({time_per_image_ms:.2f} ms/imagen)\")\n",
        "        results.append([model_name, batch_size, fps, time_per_image_ms])\n",
        "\n",
        "# --- Mostrar tabla de resultados ---\n",
        "df = pd.DataFrame(results, columns=['Modelo', 'Batch Size', 'FPS', 'Tiempo por Imagen (ms)'])\n",
        "print(\"\\n\\n\" + \"=\"*60)\n",
        "print(\"üìä RESUMEN FINAL DE RENDIMIENTO üìä\")\n",
        "print(\"=\"*60)\n",
        "print(df.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5zTu0rrQVgq",
        "outputId": "65fc3f68-9fdc-4400-e515-1dfe9256fad9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Iniciando Test de Inferencia de FPS en Google Colab ---\n",
            "‚úÖ GPU detectada: 0\n",
            "\n",
            "Cargando im√°genes de prueba...\n",
            "Total de im√°genes cargadas: 210\n",
            "\n",
            "==================================================\n",
            "Analizando: Modelo B0 (EfficientNetV2-B0)\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'aspp_module_4', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'deformable_attention_4', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Probando con Batch Size = 1 ---\n",
            "Resultados: 126.76 FPS (7.89 ms/imagen)\n",
            "\n",
            "--- Probando con Batch Size = 8 ---\n",
            "Resultados: 451.00 FPS (2.22 ms/imagen)\n",
            "\n",
            "--- Probando con Batch Size = 16 ---\n",
            "Resultados: 575.68 FPS (1.74 ms/imagen)\n",
            "\n",
            "--- Probando con Batch Size = 32 ---\n",
            "Resultados: 633.63 FPS (1.58 ms/imagen)\n",
            "\n",
            "--- Probando con Batch Size = 64 ---\n",
            "Resultados: 626.10 FPS (1.60 ms/imagen)\n",
            "\n",
            "--- Probando con Batch Size = 100 ---\n",
            "Resultados: 594.00 FPS (1.68 ms/imagen)\n",
            "\n",
            "==================================================\n",
            "Analizando: Modelo S (EfficientNetV2-S)\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'aspp_module', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'deformable_attention', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Probando con Batch Size = 1 ---\n",
            "Resultados: 88.22 FPS (11.34 ms/imagen)\n",
            "\n",
            "--- Probando con Batch Size = 8 ---\n",
            "Resultados: 389.62 FPS (2.57 ms/imagen)\n",
            "\n",
            "--- Probando con Batch Size = 16 ---\n",
            "Resultados: 497.96 FPS (2.01 ms/imagen)\n",
            "\n",
            "--- Probando con Batch Size = 32 ---\n",
            "Resultados: 564.80 FPS (1.77 ms/imagen)\n",
            "\n",
            "--- Probando con Batch Size = 64 ---\n",
            "Resultados: 590.44 FPS (1.69 ms/imagen)\n",
            "\n",
            "--- Probando con Batch Size = 100 ---\n",
            "Resultados: 597.34 FPS (1.67 ms/imagen)\n",
            "\n",
            "\n",
            "============================================================\n",
            "üìä RESUMEN FINAL DE RENDIMIENTO üìä\n",
            "============================================================\n",
            "                       Modelo  Batch Size        FPS  Tiempo por Imagen (ms)\n",
            "Modelo B0 (EfficientNetV2-B0)           1 126.757984                7.889049\n",
            "Modelo B0 (EfficientNetV2-B0)           8 450.995534                2.217317\n",
            "Modelo B0 (EfficientNetV2-B0)          16 575.681784                1.737071\n",
            "Modelo B0 (EfficientNetV2-B0)          32 633.634504                1.578197\n",
            "Modelo B0 (EfficientNetV2-B0)          64 626.099723                1.597190\n",
            "Modelo B0 (EfficientNetV2-B0)         100 593.996454                1.683512\n",
            "  Modelo S (EfficientNetV2-S)           1  88.221397               11.335119\n",
            "  Modelo S (EfficientNetV2-S)           8 389.615452                2.566633\n",
            "  Modelo S (EfficientNetV2-S)          16 497.961574                2.008187\n",
            "  Modelo S (EfficientNetV2-S)          32 564.796721                1.770549\n",
            "  Modelo S (EfficientNetV2-S)          64 590.438656                1.693656\n",
            "  Modelo S (EfficientNetV2-S)         100 597.338802                1.674092\n"
          ]
        }
      ]
    }
  ]
}