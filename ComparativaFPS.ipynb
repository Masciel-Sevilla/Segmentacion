{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "mount_file_id": "1LnNQVVqOt2wsrCt_9AEVLhJWUpIC3FNY",
      "authorship_tag": "ABX9TyMAwzAYL2bEsxFSKKU+3WkE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Masciel-Sevilla/Segmentacion/blob/main/ComparativaFPS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rt79bwyoPuZE",
        "outputId": "88e6f24e-d398-4c5b-e020-52bb7f493885"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Descomprimiendo /content/Balanced.zip...\n",
            "¡Descompresión completada!\n"
          ]
        }
      ],
      "source": [
        "# Paso 1: Descomprimir el dataset (esto solo se hace una vez)\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "zip_path = '/content/Balanced.zip'\n",
        "extract_path = '/content/'\n",
        "\n",
        "# Solo descomprimir si no se ha hecho antes\n",
        "if not os.path.exists(os.path.join(extract_path, 'Balanced')):\n",
        "    print(f\"Descomprimiendo {zip_path}...\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "    print(\"¡Descompresión completada!\")\n",
        "else:\n",
        "    print(\"La carpeta 'Balanced' ya existe. Omitiendo descompresión.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "from glob import glob\n",
        "from tensorflow.keras import layers\n",
        "import pandas as pd\n",
        "\n",
        "class ASPPModule(layers.Layer):\n",
        "    def __init__(self, filters=192, **kwargs):\n",
        "        super(ASPPModule, self).__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.conv_1x1 = layers.Conv2D(filters, 1, padding='same', use_bias=False)\n",
        "        self.bn_1x1 = layers.BatchNormalization()\n",
        "        self.relu_1x1 = layers.ReLU()\n",
        "        self.conv_3x3_6 = layers.Conv2D(filters, 3, padding='same', dilation_rate=6, use_bias=False)\n",
        "        self.bn_3x3_6 = layers.BatchNormalization()\n",
        "        self.relu_3x3_6 = layers.ReLU()\n",
        "        self.conv_3x3_12 = layers.Conv2D(filters, 3, padding='same', dilation_rate=12, use_bias=False)\n",
        "        self.bn_3x3_12 = layers.BatchNormalization()\n",
        "        self.relu_3x3_12 = layers.ReLU()\n",
        "        self.conv_3x3_18 = layers.Conv2D(filters, 3, padding='same', dilation_rate=18, use_bias=False)\n",
        "        self.bn_3x3_18 = layers.BatchNormalization()\n",
        "        self.relu_3x3_18 = layers.ReLU()\n",
        "        self.global_avg_pool = layers.GlobalAveragePooling2D(keepdims=True)\n",
        "        self.conv_1x1_gap = layers.Conv2D(filters, 1, padding='same', use_bias=False)\n",
        "        self.bn_1x1_gap = layers.BatchNormalization()\n",
        "        self.relu_1x1_gap = layers.ReLU()\n",
        "        self.conv_final = layers.Conv2D(filters, 1, padding='same', use_bias=False)\n",
        "        self.bn_final = layers.BatchNormalization()\n",
        "        self.relu_final = layers.ReLU()\n",
        "        self.dropout = layers.Dropout(0.2)\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        conv_1x1 = self.relu_1x1(self.bn_1x1(self.conv_1x1(inputs), training=training))\n",
        "        conv_3x3_6 = self.relu_3x3_6(self.bn_3x3_6(self.conv_3x3_6(inputs), training=training))\n",
        "        conv_3x3_12 = self.relu_3x3_12(self.bn_3x3_12(self.conv_3x3_12(inputs), training=training))\n",
        "        conv_3x3_18 = self.relu_3x3_18(self.bn_3x3_18(self.conv_3x3_18(inputs), training=training))\n",
        "        gap = self.global_avg_pool(inputs)\n",
        "        gap = self.relu_1x1_gap(self.bn_1x1_gap(self.conv_1x1_gap(gap), training=training))\n",
        "        gap = tf.image.resize(gap, [input_shape[1], input_shape[2]], method='bilinear')\n",
        "        concat = layers.Concatenate()([conv_1x1, conv_3x3_6, conv_3x3_12, conv_3x3_18, gap])\n",
        "        output = self.relu_final(self.bn_final(self.conv_final(concat), training=training))\n",
        "        output = self.dropout(output, training=training)\n",
        "        return output\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(ASPPModule, self).get_config()\n",
        "        config.update({\"filters\": self.filters})\n",
        "        return config\n",
        "\n",
        "class DeformableAttention(layers.Layer):\n",
        "    def __init__(self, filters, **kwargs):\n",
        "        super(DeformableAttention, self).__init__(**kwargs)\n",
        "        self.filters = filters\n",
        "        self.attention_conv = layers.Conv2D(self.filters, 1, padding='same', activation='sigmoid', name='attention_weights_conv', use_bias=False)\n",
        "        self.bn_attention = layers.BatchNormalization()\n",
        "        self.feature_conv = layers.SeparableConv2D(self.filters, 3, padding='same', name='feature_processing_conv', use_bias=False)\n",
        "        self.bn_feature = layers.BatchNormalization()\n",
        "        self.relu_feature = layers.ReLU()\n",
        "\n",
        "    def call(self, inputs, training=None):\n",
        "        attention_weights = self.bn_attention(self.attention_conv(inputs), training=training)\n",
        "        features = self.relu_feature(self.bn_feature(self.feature_conv(inputs), training=training))\n",
        "        attended_features = features * attention_weights\n",
        "        return attended_features\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(DeformableAttention, self).get_config()\n",
        "        config.update({\"filters\": self.filters})\n",
        "        return config\n",
        "\n",
        "# =============================================================================\n",
        "# CONFIGURACIÓN\n",
        "# =============================================================================\n",
        "MODELS_TO_TEST = [\n",
        "    {'name': 'Modelo B0 (EfficientNetV2-B0)', 'path': 'efficient_weed_model_B0_best.keras'},\n",
        "    {'name': 'Modelo S (EfficientNetV2-S)', 'path': 'efficient_weed_model_S_best.keras'}\n",
        "]\n",
        "# --- ¡NUEVO! Lista de batch sizes a probar ---\n",
        "BATCH_SIZES_TO_TEST = [1, 8, 16, 32, 64, 100]\n",
        "\n",
        "TEST_IMAGES_PATH = './Balanced/test/images'\n",
        "IMG_HEIGHT, IMG_WIDTH = 128, 128\n",
        "\n",
        "# =============================================================================\n",
        "# SCRIPT PRINCIPAL\n",
        "# =============================================================================\n",
        "print(\"--- Iniciando Test de Inferencia de FPS en Google Colab ---\")\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    print(f\"✅ GPU detectada: {gpus[0].name.split(':')[-1]}\")\n",
        "else:\n",
        "    print(\"❌ No se detectó ninguna GPU.\")\n",
        "\n",
        "# Cargar todas las imágenes de prueba una sola vez\n",
        "print(f\"\\nCargando imágenes de prueba...\")\n",
        "all_image_paths = sorted(glob(os.path.join(TEST_IMAGES_PATH, '*.jpg')))\n",
        "all_test_images = [tf.keras.applications.efficientnet_v2.preprocess_input(tf.image.resize(tf.image.decode_jpeg(tf.io.read_file(path), channels=3), [IMG_HEIGHT, IMG_WIDTH])) for path in all_image_paths]\n",
        "all_test_images = np.array(all_test_images)\n",
        "print(f\"Total de imágenes cargadas: {len(all_test_images)}\")\n",
        "\n",
        "# --- Almacenar resultados ---\n",
        "results = []\n",
        "custom_objects = {'ASPPModule': ASPPModule, 'DeformableAttention': DeformableAttention}\n",
        "\n",
        "# Bucle para probar cada modelo\n",
        "for model_info in MODELS_TO_TEST:\n",
        "    model_name = model_info['name']\n",
        "    model_path = model_info['path']\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(f\"Analizando: {model_name}\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    if not os.path.exists(model_path):\n",
        "        print(f\"❌ ERROR: No se encontró el archivo del modelo: {model_path}. Omitiendo.\")\n",
        "        continue\n",
        "\n",
        "    model = tf.keras.models.load_model(model_path, custom_objects=custom_objects, compile=False)\n",
        "\n",
        "    # Bucle para probar cada batch size\n",
        "    for batch_size in BATCH_SIZES_TO_TEST:\n",
        "        print(f\"\\n--- Probando con Batch Size = {batch_size} ---\")\n",
        "\n",
        "        # Seleccionar el número correcto de imágenes\n",
        "        num_images = (len(all_test_images) // batch_size) * batch_size\n",
        "        if num_images == 0:\n",
        "            print(\"No hay suficientes imágenes para este batch size. Omitiendo.\")\n",
        "            continue\n",
        "\n",
        "        test_images_batch = all_test_images[:num_images]\n",
        "\n",
        "        # Calentamiento\n",
        "        _ = model.predict(test_images_batch[:batch_size], verbose=0, batch_size=batch_size)\n",
        "\n",
        "        # Medición\n",
        "        start_time = time.time()\n",
        "        _ = model.predict(test_images_batch, verbose=0, batch_size=batch_size)\n",
        "        end_time = time.time()\n",
        "\n",
        "        total_time = end_time - start_time\n",
        "        fps = num_images / total_time\n",
        "        time_per_image_ms = (total_time / num_images) * 1000\n",
        "\n",
        "        print(f\"Resultados: {fps:.2f} FPS ({time_per_image_ms:.2f} ms/imagen)\")\n",
        "        results.append([model_name, batch_size, fps, time_per_image_ms])\n",
        "\n",
        "# --- Mostrar tabla de resultados ---\n",
        "df = pd.DataFrame(results, columns=['Modelo', 'Batch Size', 'FPS', 'Tiempo por Imagen (ms)'])\n",
        "print(\"\\n\\n\" + \"=\"*60)\n",
        "print(\"📊 RESUMEN FINAL DE RENDIMIENTO 📊\")\n",
        "print(\"=\"*60)\n",
        "print(df.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5zTu0rrQVgq",
        "outputId": "65fc3f68-9fdc-4400-e515-1dfe9256fad9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Iniciando Test de Inferencia de FPS en Google Colab ---\n",
            "✅ GPU detectada: 0\n",
            "\n",
            "Cargando imágenes de prueba...\n",
            "Total de imágenes cargadas: 210\n",
            "\n",
            "==================================================\n",
            "Analizando: Modelo B0 (EfficientNetV2-B0)\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'aspp_module_4', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'deformable_attention_4', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Probando con Batch Size = 1 ---\n",
            "Resultados: 126.76 FPS (7.89 ms/imagen)\n",
            "\n",
            "--- Probando con Batch Size = 8 ---\n",
            "Resultados: 451.00 FPS (2.22 ms/imagen)\n",
            "\n",
            "--- Probando con Batch Size = 16 ---\n",
            "Resultados: 575.68 FPS (1.74 ms/imagen)\n",
            "\n",
            "--- Probando con Batch Size = 32 ---\n",
            "Resultados: 633.63 FPS (1.58 ms/imagen)\n",
            "\n",
            "--- Probando con Batch Size = 64 ---\n",
            "Resultados: 626.10 FPS (1.60 ms/imagen)\n",
            "\n",
            "--- Probando con Batch Size = 100 ---\n",
            "Resultados: 594.00 FPS (1.68 ms/imagen)\n",
            "\n",
            "==================================================\n",
            "Analizando: Modelo S (EfficientNetV2-S)\n",
            "==================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'aspp_module', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/layer.py:421: UserWarning: `build()` was called on layer 'deformable_attention', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Probando con Batch Size = 1 ---\n",
            "Resultados: 88.22 FPS (11.34 ms/imagen)\n",
            "\n",
            "--- Probando con Batch Size = 8 ---\n",
            "Resultados: 389.62 FPS (2.57 ms/imagen)\n",
            "\n",
            "--- Probando con Batch Size = 16 ---\n",
            "Resultados: 497.96 FPS (2.01 ms/imagen)\n",
            "\n",
            "--- Probando con Batch Size = 32 ---\n",
            "Resultados: 564.80 FPS (1.77 ms/imagen)\n",
            "\n",
            "--- Probando con Batch Size = 64 ---\n",
            "Resultados: 590.44 FPS (1.69 ms/imagen)\n",
            "\n",
            "--- Probando con Batch Size = 100 ---\n",
            "Resultados: 597.34 FPS (1.67 ms/imagen)\n",
            "\n",
            "\n",
            "============================================================\n",
            "📊 RESUMEN FINAL DE RENDIMIENTO 📊\n",
            "============================================================\n",
            "                       Modelo  Batch Size        FPS  Tiempo por Imagen (ms)\n",
            "Modelo B0 (EfficientNetV2-B0)           1 126.757984                7.889049\n",
            "Modelo B0 (EfficientNetV2-B0)           8 450.995534                2.217317\n",
            "Modelo B0 (EfficientNetV2-B0)          16 575.681784                1.737071\n",
            "Modelo B0 (EfficientNetV2-B0)          32 633.634504                1.578197\n",
            "Modelo B0 (EfficientNetV2-B0)          64 626.099723                1.597190\n",
            "Modelo B0 (EfficientNetV2-B0)         100 593.996454                1.683512\n",
            "  Modelo S (EfficientNetV2-S)           1  88.221397               11.335119\n",
            "  Modelo S (EfficientNetV2-S)           8 389.615452                2.566633\n",
            "  Modelo S (EfficientNetV2-S)          16 497.961574                2.008187\n",
            "  Modelo S (EfficientNetV2-S)          32 564.796721                1.770549\n",
            "  Modelo S (EfficientNetV2-S)          64 590.438656                1.693656\n",
            "  Modelo S (EfficientNetV2-S)         100 597.338802                1.674092\n"
          ]
        }
      ]
    }
  ]
}